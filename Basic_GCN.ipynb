{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Basic_GCN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpGzydPCWtu"
      },
      "source": [
        "# Building a GCN from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM6_ezunCWty"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joerg84/Graph_Powered_ML_Workshop/blob/master/Basic_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_HvA7FKCWty"
      },
      "source": [
        "First, setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiSolFbjCWty"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/joerg84/Graph_Powered_ML_Workshop.git\n",
        "!rsync -av Graph_Powered_ML_Workshop/ ./ --exclude=.git\n",
        "!pip3 install dgl\n",
        "!pip3 install numpy\n",
        "!pip3 install torch\n",
        "!pip3 install networkx\n",
        "!pip3 install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7yqEw7CCWtz"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bgeVkycCWtz"
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyvt4sDZCWtz"
      },
      "source": [
        "Let us built a toy GCN from scratch (inspired by https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvODbEUjCWt0"
      },
      "source": [
        "#Graph expressed by the adjacency matrix\n",
        "A = np.matrix([\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 1, 1], \n",
        "    [0, 1, 0, 0],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "# Draw the graph \n",
        "G = nx.from_numpy_array(A, create_using=nx.DiGraph())\n",
        "nx.draw(G, with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIVRlMTgCWt0"
      },
      "source": [
        "Next, we need to add some features to the edges. For simpliclicity we will use two floats (+/- the node's id)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrGw99I4CWt0"
      },
      "source": [
        "X = np.matrix([\n",
        "            [i, -i]\n",
        "            for i in range(A.shape[0])\n",
        "        ], dtype=float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXUPYqEuCWt0"
      },
      "source": [
        "A GCN hidden layer can be seen Hⁱ = f(Hⁱ⁻¹, A)) where A is the adjacency matrix of the graph, Hⁱ⁻¹ is the previous layer (and hence H⁰ = X = feature vector). f() is our respective propagation function specifying how features are aggregated. \n",
        "The most basic function imaginable would be f(X, A) = AX (not too meaningful, but helpful to understand the concept)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPATpYXMCWt0"
      },
      "source": [
        "h_1 = A * X\n",
        "print(h_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9BzQDLKCWt1"
      },
      "source": [
        "So every node feature is now the sum if its direct neighbours. Note that we are working with a directed graphs and the a directed edge from 0 to 1 indicated that 1 is a neighbour of 0 but note vice versa (so the messages flow opposite to the arrows in the above visualization)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBqLVwpsCWt1"
      },
      "source": [
        "This would represent a GCN with just a single layer and means the features in the output are only influenced by the direct neighbours and not even the node value itself, but we fix that next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z6hhelbCWt1"
      },
      "source": [
        "# We can simply extend our adjacency matrix with a self-loop to preserve the current node value\n",
        "I = np.matrix(np.eye(A.shape[0]))\n",
        "A_hat = A + I\n",
        "\n",
        "h1_hat = A_hat * X\n",
        "print(h1_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS39ZrLNCWt1"
      },
      "source": [
        "Still nodes with more neighbours will accumulate higher values, but we can use the degree (i.e., number of neighbours) to normalize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaXuOHWCWt1"
      },
      "source": [
        "# First compute the degree matrix of A\n",
        "D = np.array(np.sum(A, axis=0))[0]\n",
        "D = np.matrix(np.diag(D))\n",
        "print(D)\n",
        "print()\n",
        "\n",
        "# Also compute the degree matrix of A_hat\n",
        "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
        "D_hat = np.matrix(np.diag(D_hat))\n",
        "print(D_hat)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iwpn0GrCWt1"
      },
      "source": [
        "# Next we use that to normalize our A_hat\n",
        "A_hat_2 = D_hat**-1 * A_hat\n",
        "\n",
        "h_hat_2 = A_hat_2 * X\n",
        "print(h_hat_2)\n",
        "print()\n",
        "\n",
        "print(\"Just to recall the degree of each node (including the self loop):\")\n",
        "print(np.diag(D_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phZHxRPoCWt2"
      },
      "source": [
        "Note that compared to h1_hat the values have been divided by the degree of each node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuCorPSKCWt2"
      },
      "source": [
        "Our current propagation function f(X, A) = A_hat_2 * X is static and there are no parameters we could learn.\n",
        "Let us add weights f(Hⁱ, A) = AHⁱWⁱ and hence allow for our network to be trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWwrUdMXCWt2"
      },
      "source": [
        "W = np.matrix([\n",
        "             [1, -1],\n",
        "             [-1, 1]\n",
        "         ])\n",
        "\n",
        "h_hat_3 = A_hat_2 * X * W\n",
        "(print(h_hat_3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzehDOGYCWt2"
      },
      "source": [
        "The last missing piece is to add a non-linear activiation function: f(Hⁱ, A) = σ(AHⁱWⁱ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gChL_B0pCWt2"
      },
      "source": [
        "def relu(X):\n",
        "   return np.maximum(0,X)\n",
        "\n",
        "h_hat_4 = relu(A_hat_2 * X * W)\n",
        "(print(h_hat_4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y01d1OLYCWt2"
      },
      "source": [
        "Congratulation, you have built a GCN hidden layer with adjacency matrix, features, weights and a relu activation function from scratch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjkic1j6CWt3"
      },
      "source": [
        "# Back to the Karate Club!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3aWvHUFCWt3"
      },
      "source": [
        "![karate](https://github.com/joerg84/Graph_Powered_ML_Workshop/blob/master/img/karate_club.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFBB83OYCWt3"
      },
      "source": [
        "# We use the karate club representation from networkx\n",
        "zkc = nx.karate_club_graph()\n",
        "order = sorted(list(zkc.nodes()))\n",
        "\n",
        "nx.draw(zkc, with_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNdCb5KxCrAf"
      },
      "source": [
        "Let us extract the adjacency matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weZpnU9jCWt3"
      },
      "source": [
        "A = nx.to_numpy_matrix(zkc, nodelist=order)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryNAhHFrCWt3"
      },
      "source": [
        "# As before add self-loops \n",
        "num_nodes = A.shape[0]\n",
        "I = np.matrix(np.eye(num_nodes))\n",
        "A_hat = A + I\n",
        "\n",
        "# And create degree matrix\n",
        "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
        "D_hat = np.matrix(np.diag(D_hat))\n",
        "\n",
        "print(D_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp0vbCyrCWt3"
      },
      "source": [
        "As we will learn them later, let us initialize the weights randomly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqhiOVrDCWt3"
      },
      "source": [
        "W_1 = np.random.normal(\n",
        "    loc=0, scale=1, size=(num_nodes, 4))\n",
        "W_2 = np.random.normal(\n",
        "    loc=0, size=(W_1.shape[1], 2))\n",
        "\n",
        "print(W_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYdEbbPhCWt4"
      },
      "source": [
        "For readability we create a helper function for the hidden layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bajLiq_iCWt4"
      },
      "source": [
        "def gcn_layer(A_hat, D_hat, X, W):\n",
        "    return relu(D_hat**-1 * A_hat * X * W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwfv9-TKCWt4"
      },
      "source": [
        "With that we are ready to specify a two layer GCN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmBVBAuGCWt4"
      },
      "source": [
        "# As input we use the identity matrix, i.e., each node is represented as a one-hot encoded categorical variable.\n",
        "H_0 = np.matrix(np.eye(num_nodes)) \n",
        "\n",
        "H_1 = gcn_layer(A_hat, D_hat, H_0, W_1)\n",
        "H_2 = gcn_layer(A_hat, D_hat, H_1, W_2)\n",
        "\n",
        "output = H_2\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDoh2efbCWt4"
      },
      "source": [
        "Let us look at the output (keeping in mind we haven't trained the network yet and the weights are random!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUgc2B19CWt4"
      },
      "source": [
        "for node in range(34):\n",
        "    print(node)\n",
        "    print(output[node])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUN5morECWt4"
      },
      "source": [
        "In the next notebook we will actually train a GCN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu0n6-w7CWt4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}