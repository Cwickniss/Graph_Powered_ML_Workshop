{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a GCN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/joerg84/Graph_Powered_ML_Workshop/blob/master/Basic_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/joerg84/Graph_Powered_ML_Workshop.git\n",
    "!rsync -av Graph_Powered_ML_Workshop/ ./ --exclude=.git\n",
    "!pip3 install dgl\n",
    "!pip3 install numpy\n",
    "!pip3 install torch\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us built a toy GCN from scratch (inspired by https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph expressed by the adjacency matrix\n",
    "A = np.matrix([\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 1], \n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 1, 0]],\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "# Draw the graph \n",
    "G = nx.from_numpy_array(A, create_using=nx.DiGraph())\n",
    "nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to add some features to the edges. For simpliclicity we will use two floats (+/- the node's id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix([\n",
    "            [i, -i]\n",
    "            for i in range(A.shape[0])\n",
    "        ], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GCN hidden layer can be seen Hⁱ = f(Hⁱ⁻¹, A)) where A is the adjacency matrix of the graph, Hⁱ⁻¹ is the previous layer (and hence H⁰ = X = feature vector). f() is our respective propagation function specifying how features are aggregated. \n",
    "The most basic function imaginable would be f(X, A) = AX (not too meaningful, but helpful to understand the concept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = A * X\n",
    "print(h_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So every node feature is now the sum if its direct neighbours. Note that we are working with a directed graphs and the a directed edge from 0 to 1 indicated that 1 is a neighbour of 0 but note vice versa (so the messages flow opposite to the arrows in the above visualization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would represent a GCN with just a single layer and means the features in the output are only influenced by the direct neighbours and not even the node value itself, but we fix that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can simply extend our adjacency matrix with a self-loop to preserve the current node value\n",
    "I = np.matrix(np.eye(A.shape[0]))\n",
    "A_hat = A + I\n",
    "\n",
    "h1_hat = A_hat * X\n",
    "print(h1_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still nodes with more neighbours will accumulate higher values, but we can use the degree (i.e., number of neighbours) to normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First compute the degree matrix of A\n",
    "D = np.array(np.sum(A, axis=0))[0]\n",
    "D = np.matrix(np.diag(D))\n",
    "print(D)\n",
    "print()\n",
    "\n",
    "# Also compute the degree matrix of A_hat\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
    "D_hat = np.matrix(np.diag(D_hat))\n",
    "print(D_hat)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we use that to normalize our A_hat\n",
    "A_hat_2 = D_hat**-1 * A_hat\n",
    "\n",
    "h_hat_2 = A_hat_2 * X\n",
    "print(h_hat_2)\n",
    "print()\n",
    "\n",
    "print(\"Just to recall the degree of each node (including the self loop):\")\n",
    "print(np.diag(D_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that compared to h1_hat the values have been divided by the degree of each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current propagation function f(X, A) = A_hat_2 * X is static and there are no parameters we could learn.\n",
    "Let us add weights f(Hⁱ, A) = AHⁱWⁱ and hence allow for our network to be trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.matrix([\n",
    "             [1, -1],\n",
    "             [-1, 1]\n",
    "         ])\n",
    "\n",
    "h_hat_3 = A_hat_2 * X * W\n",
    "(print(h_hat_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last missing piece is to add a non-linear activiation function: f(Hⁱ, A) = σ(AHⁱWⁱ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "   return np.maximum(0,X)\n",
    "\n",
    "h_hat_4 = relu(A_hat_2 * X * W)\n",
    "(print(h_hat_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulation, you have built a GCN hidden layer with adjacency matrix, features, weights and a relu activation function from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the Karate Club!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karate](https://github.com/joerg84/Graph_Powered_ML_Workshop/blob/master/img/karate_club.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the karate club representation from networkx\n",
    "zkc = nx.karate_club_graph()\n",
    "order = sorted(list(zkc.nodes()))\n",
    "\n",
    "nx.draw(zkc, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us extract the adjacency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_matrix(zkc, nodelist=order)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before add self-loops \n",
    "num_nodes = A.shape[0]\n",
    "I = np.matrix(np.eye(num_nodes))\n",
    "A_hat = A + I\n",
    "\n",
    "# And create degree matrix\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
    "D_hat = np.matrix(np.diag(D_hat))\n",
    "\n",
    "print(D_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will learn them later, let us initialize the weights randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = np.random.normal(\n",
    "    loc=0, scale=1, size=(num_nodes, 4))\n",
    "W_2 = np.random.normal(\n",
    "    loc=0, size=(W_1.shape[1], 2))\n",
    "\n",
    "print(W_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For readability we create a helper function for the hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn_layer(A_hat, D_hat, X, W):\n",
    "    return relu(D_hat**-1 * A_hat * X * W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we are ready to specify a two layer GCN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As input we use the identity matrix, i.e., each node is represented as a one-hot encoded categorical variable.\n",
    "H_0 = np.matrix(np.eye(num_nodes)) \n",
    "\n",
    "H_1 = gcn_layer(A_hat, D_hat, H_0, W_1)\n",
    "H_2 = gcn_layer(A_hat, D_hat, H_1, W_2)\n",
    "\n",
    "output = H_2\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the output (keeping in mind we haven't trained the network yet and the weights are random!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in range(34):\n",
    "    print(node)\n",
    "    print(output[node])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we will actually train a GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Basic_GCN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
